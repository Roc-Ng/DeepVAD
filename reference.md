# Deep Learning for Video Anomaly Detection: A Review

This is the official repository for the paper entitled "**Deep Learning for Video Anomaly Detection: A Review**". 

## ğŸ“– Table of contents

- [Existing Reviews](#reviews)
- [Our Taxonomy](#taxonomy)
  - [1. Semi-Supervised Video Anomaly Detection](#1-Semi-Supervised-Video-Anomaly-Detection)
    - [1.1 Model Input](#11-Model-Input)
      - [1.1.1 RGB](#111-RGB)
      - [1.1.2 Optical Flow](#112-Optical-Flow)
      - [1.1.3 Skeleton](#113-Skeleton)
      - [1.1.4 Hybrid](#114-Hybrid)
    - [1.2 Methodology](#12-Methodology)
      - [1.2.1 Self-Supervised Learning](#121-Self-Supervised-Learning)
      - [1.2.2 One-Class Learning](#122-One-Class-Learning)
      - [1.2.3 Interpretable Learning](#123-Interpretable-Learning)
    - [1.3 Network Architecture](#13-Network-Architecture)
      - [1.3.1 Auto-Encoder](#131-Auto-Encoder)
      - [1.3.2 GAN](#132-GAN)
      - [1.3.3 Diffusion](#133-Diffusion)
    - [1.4 Model Refinement](#14-Model-Refinement)
      - [1.4.1 Pseudo Anomalies](#141-Pseudo-Anomalies)
      - [1.4.2 Memory Bank](#142-Memory-Bank)
    - [1.5 Model Output](#15-Model-Output)
      - [1.5.1 Frame Level](#151-Frame-level)
      - [1.5.2 Pixel Level](#152-Pixel-level)
  - [2. Weakly Supervised Video Anomaly Detection](#2-weakly-supervised-video-anomaly-detection)
    - [2.1 Model Input](#21-Model-Input)
      - [2.1.1 RGB](#211-RGB)
      - [2.1.2 Optical Flow](#212-Optical-Flow)
      - [2.1.3 Audio](#213-Audio)
      - [2.1.4 Text](#214-Text)
      - [2.1.5 Hybrid](#215-Hybrid)
    - [2.2 Methodology](#22-methodology)
      - [2.2.1 One-Stage MIL](#221-One-Stage-MIL)
      - [2.2.2 Two-Stage Self-Training](#222-Two-Stage-Self-Training)
    - [2.3 Refinement Strategy](#23-Refinement-Strategy)
      - [2.3.1 Temporal Modeling](#231-Temporal-Modeling)
      - [2.3.2 Spatio-Temporal Modeling](#232-Spatio-Temporal-Modeling)
      - [2.3.3 MIL-Based Refinement](#233-MIL-Based-Refinement)
      - [2.3.4 Feature Metric Learning](#234-Feature-Metric-Learning)
      - [2.3.5 Knowledge Distillation](#235-Knowledge-Distillation)
      - [2.3.6 Leveraging Large Models](#236-Leveraging-Large-Models)
    - [2.4 Model Output](#24-Model-Output)
      - [2.4.1 Frame Level](#241-Frame-Level)
      - [2.4.2 Pixel Level](#242-Pixel-Level)
  - [3. Fully Supervised Video Anomaly Detection](#3-Fully-Supervised-Video-Anomaly-Detection)
    - [3.1 Appearance Input](#31-Appearance-Input)
    - [3.2 Motion Input](#32-Motion-Input)
    - [3.3 Skeleton Input](#33-Skeleton-Input)
    - [3.4 Audio Input](#34-Audio-Input)
    - [3.5 Hybrid Input](#35-Hybrid-Input)
  - [4. Unsupervised Video Anomaly Detection](#4-Unsupervised-Video-Anomaly-Detection)
    - [4.1 Pseudo Label Based Paradigm](#41-Pseudo-Label-Based-Paradigm)
    - [4.2 Change Detection Based Paradigm](#42-Change-Detection-Based-Paradigm)
    - [4.3 Others](#43-Others)
  - [5. Open-Set Supervised Video Anomaly Detection](#5-Open-Set-Supervised-Video-Anomaly-Detection)
    - [5.1 Open-Set VAD](#51-Open-Set-VAD)
    - [5.2 Few-Shot VAD](#52-Few-Shot-VAD)
- [Performance Comparison](#performance-comparison)
- [Citation](#citation)

## Reviews

| Reference                                                                           | Year | Venue               | Main Focus                                 | Main Categorization                                              | UVAD | WVAD | SVAD | FVAD | OVAD | LVAD | IVAD |
|:----------------------------------------------------------------------------------- |:----:|:-------------------:|:------------------------------------------:|:----------------------------------------------------------------:|:----:|:----:|:----:|:----:|:----:|:----:| ---- |
| [Ramachandra et al.](https://ieeexplore.ieee.org/abstract/document/9271895)         | 2020 | IEEE TPAMI          | Semi-supervised single-scene VAD           | Methodology                                                      | Ã—    | Ã—    | âˆš    | Ã—    | Ã—    | Ã—    | Ã—    |
| [Santhosh et al.](https://dl.acm.org/doi/abs/10.1145/3417989)                       | 2020 | ACM CSUR            | VAD applied on road traffic                | Methodology                                                      | âˆš    | Ã—    | âˆš    | âˆš    | Ã—    | Ã—    | Ã—    |
| [Nayak et al.](https://www.sciencedirect.com/science/article/pii/S0262885620302109) | 2021 | IMAVIS              | Deep learning driven semi-supervised VAD   | Methodology                                                      | Ã—    | Ã—    | âˆš    | Ã—    | Ã—    | Ã—    | Ã—    |
| [Tran et al.](https://dl.acm.org/doi/abs/10.1145/3544014)                           | 2022 | ACM CSUR            | Semi&weakly supervised VAD                 | Architecture                                                     | Ã—    | Ã—    | âˆš    | Ã—    | Ã—    | Ã—    | Ã—    |
| [Chandrakala et al.](https://link.springer.com/article/10.1007/s10462-022-10258-6)  | 2023 | Artif. Intell. Rev. | Deep model-based one&two-class VAD         | Methodology&Architecture                                         | Ã—    | âˆš    | âˆš    | âˆš    | Ã—    | Ã—    | Ã—    |
| [Liu et al.](https://dl.acm.org/doi/abs/10.1145/3645101)                            | 2023 | ACM CSUR            | Deep models for semi&weakly supervised VAD | Model Input                                                      | âˆš    | âˆš    | âˆš    | âˆš    | Ã—    | Ã—    | Ã—    |
| Our survey                                                                          | 2024 | -                   | Comprehensive VAD taxonomy and deep models | Methodology, Architecture, Refinement, Model Input, Model Output | âˆš    | âˆš    | âˆš    | âˆš    | âˆš    | âˆš    | âˆš    |

*UVAD=Unsupervised VAD, WVAD=Weakly supervised VAD, SVAD=Semi-supervised VAD, FVAD=Fully supervised VAD, OVAD=Open-set supervised VAD, LVAD: Large-model based VAD, IVAD: Interpretable VAD*

## Taxonomy

## 1. Semi-Supervised Video Anomaly Detection

### 1.1 Model Input

#### 1.1.1 RGB

**Frame-Level RGB**

ğŸ—“ï¸ **2016**

- ğŸ“„ [ConvAE](https://openaccess.thecvf.com/content_cvpr_2016/html/Hasan_Learning_Temporal_Regularity_CVPR_2016_paper.html):Learning temporal regularity in video sequences, ğŸ“° `CVPR` [code](https://github.com/mhasa004/caffe) [homepage](https://mhasa004.github.io/regularity.html)

ğŸ—“ï¸ **2017**

- ğŸ“„ [ConvLSTM-AE](https://ieeexplore.ieee.org/abstract/document/8019325/):Remembering history with convolutional LSTM for anomaly detection, ğŸ“° `ICCV` [code](https://github.com/zachluo/convlstm_anomaly_detection)

- ğŸ“„ [STAE](https://dl.acm.org/doi/abs/10.1145/3123266.3123451): Spatio-temporal autoencoder for video anomaly detection, ğŸ“° `ACM MM`

- ğŸ“„ [AnomalyGAN](https://ieeexplore.ieee.org/abstract/document/8296547): Abnormal event detection in videos using generative adversarial nets, ğŸ“° `ICIP`

ğŸ—“ï¸ **2019**

- ğŸ“„ [AMC](https://openaccess.thecvf.com/content_ICCV_2019/html/Nguyen_Anomaly_Detection_in_Video_Sequence_With_Appearance-Motion_Correspondence_ICCV_2019_paper.html): Anomaly detection in video sequence with appearance-motion correspondence, ğŸ“° `ICCV`  [code](https://github.com/nguyetn89/Anomaly_detection_ICCV2019)

**Patch-Level RGB**

ğŸ—“ï¸ **2015**

- ğŸ“„ [AMDN](https://arxiv.org/abs/1510.01553):Learning deep representations of appearance and motion for anomalous event detection, ğŸ“° `BMVC`

ğŸ—“ï¸ **2017**

- ğŸ“„ [AMDN2](https://www.sciencedirect.com/science/article/abs/pii/S1077314216301618):Detecting anomalous events in videos by learning deep representations of appearance and motion, ğŸ“° `CVIU`

- ğŸ“„ [Deep-cascade](https://ieeexplore.ieee.org/abstract/document/7858798):Deep-cascade: Cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes, ğŸ“° `TIP`

ğŸ—“ï¸ **2018**

- ğŸ“„ [S$^2$-VAE](https://ieeexplore.ieee.org/abstract/document/8513816):Generative neural networks for anomaly detection in crowded scenes, ğŸ“° `TIFS`

ğŸ—“ï¸ **2019**

- ğŸ“„ [DeepOC](https://ieeexplore.ieee.org/abstract/document/8825555):A deep one-class neural network for anomalous event detection in complex scenes, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2020**

- ğŸ“„ [GM-VAE](https://www.sciencedirect.com/science/article/abs/pii/S1077314218302674):Video anomaly detection and localization via gaussian mixture fully convolutional variational autoencoder, ğŸ“° `CVIU`

**Object-Level RGB**

ğŸ—“ï¸ **2017**

- ğŸ“„ [FRCN](https://openaccess.thecvf.com/content_iccv_2017/html/Hinami_Joint_Detection_and_ICCV_2017_paper.html):Joint detection and recounting of abnormal events by learning deep generic knowledge, ğŸ“° `ICCV`

ğŸ—“ï¸ **2019**

- ğŸ“„ [ObjectAE](https://openaccess.thecvf.com/content_CVPR_2019/html/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.html):Object-centric auto-encoders and dummy anomalies for abnormal event detection in video, ğŸ“° `CVPR` [code](https://github.com/fjchange/object_centric_VAD)

ğŸ—“ï¸ **2021**

- ğŸ“„ [HF$^2$-VAD](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Hybrid_Video_Anomaly_Detection_Framework_via_Memory-Augmented_Flow_Reconstruction_ICCV_2021_paper):A hybrid video anomaly detection framework via memory-augmented flow reconstruction and flow-guided frame prediction, ğŸ“° `ICCV` [code](https://github.com/LiUzHiAn/hf2vad)

ğŸ—“ï¸ **2022**

- ğŸ“„ [HSNBM](https://dl.acm.org/doi/abs/10.1145/3503161.3548199):Hierarchical scene normality-binding modeling for anomaly detection in surveillance videos, ğŸ“° `ACM MM` [code](https://github.com/baoqianyue/HSNBM)

- ğŸ“„ [BDPN](https://ojs.aaai.org/index.php/AAAI/article/view/19898):Comprehensive regularization in a bi-directional predictive network for video anomaly detection, ğŸ“° `AAAI`

- ğŸ“„ [ER-VAD](https://dl.acm.org/doi/abs/10.1145/3503161.3548091):Evidential reasoning for video anomaly detection, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2023**

- ğŸ“„ [HSC](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Hierarchical_Semantic_Contrast_for_Scene-Aware_Video_Anomaly_Detection_CVPR_2023_paper):Hierarchical semantic contrast for scene-aware video anomaly detection, ğŸ“° `CVPR`[code](https://github.com/shengyangsun/HSC_VAD/)

#### 1.1.2 Optical Flow

**Frame Level**

ğŸ—“ï¸ **2018**

- ğŸ“„ [FuturePred](https://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html):Future frame prediction for anomaly detectionâ€“a new baseline, ğŸ“° `CVPR`  [code](codeï¼šhttps://github.com/StevenLiuWen/ano_pred_cvpr2018)

ğŸ—“ï¸ **2020**

- ğŸ“„ [FSCN](https://www.sciencedirect.com/science/article/abs/pii/S0031320320303186):Fast sparse coding networks for anomaly detection in videos, ğŸ“° `PR` [code](https://github.com/Roc-Ng/FSCN_AnomalyDetection)
  
  ğŸ—“ï¸ **2021**

- ğŸ“„ [F$^2$PN](https://ieeexplore.ieee.org/abstract/document/9622181):Future frame prediction network for video anomaly detection, ğŸ“° `TPAMI` [code](codeï¼šhttps://github.com/StevenLiuWen/ano_pred_cvpr2018)

- ğŸ“„ [AMMC-Net](https://ojs.aaai.org/index.php/AAAI/article/view/16177):Appearance-motion memory consistency network for video anomaly detection, ğŸ“° `AAAI` [code](https://github.com/NjuHaoZhang/AMMCNet_AAAI2021)

ğŸ—“ï¸ **2022**

- ğŸ“„ [STA-Net](https://ieeexplore.ieee.org/abstract/document/9746822):Learning task-specific representation for video anomaly detection with spatialtemporal attention, ğŸ“° `ICASSP`

ğŸ—“ï¸ **2023**

- ğŸ“„ [AMSRC](https://ieeexplore.ieee.org/abstract/document/10097199):A video anomaly detection framework based on appearance-motion semantics representation consistency, ğŸ“° `ICASSP`

**Patch Level**

ğŸ—“ï¸ **2019**

- ğŸ“„ [DeepOC](https://ieeexplore.ieee.org/abstract/document/8825555):A deep one-class neural network for anomalous event detection in complex scenes, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2020**

- ğŸ“„ [ST-CaAE](https://ieeexplore.ieee.org/abstract/document/9055131):Spatial-temporal cascade autoencoder for video anomaly detection in crowded scenes, ğŸ“° `TMM`

- ğŸ“„ [Siamese-Net](https://openaccess.thecvf.com/content_WACV_2020/html/Ramachandra_Learning_a_distance_function_with_a_Siamese_network_to_localize_WACV_2020_paper.html):Learning a distance function with a siamese network to localize anomalies in videos, ğŸ“° `WACV`

**Object Level**

ğŸ—“ï¸ **2021**

- ğŸ“„ [HF$^2$-VAD](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Hybrid_Video_Anomaly_Detection_Framework_via_Memory-Augmented_Flow_Reconstruction_ICCV_2021_paper):A hybrid video anomaly detection framework via memory-augmented flow reconstruction and flow-guided frame prediction, ğŸ“° `ICCV` [code](https://github.com/LiUzHiAn/hf2vad)

ğŸ—“ï¸ **2022**

- ğŸ“„ [ER-VAD](https://dl.acm.org/doi/abs/10.1145/3503161.3548091):Evidential reasoning for video anomaly detection, ğŸ“° `ACM MM`

- ğŸ“„ [Accurate-Interpretable-VAD](https://arxiv.org/abs/2212.00789):Attribute-based representations for accurate and interpretable video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/talreiss/Accurate-Interpretable-VAD)

ğŸ—“ï¸ **2023**

- ğŸ“„ [AMSRC](https://ieeexplore.ieee.org/abstract/document/10097199):A video anomaly detection framework based on appearance-motion semantics representation consistency, ğŸ“° `ICASSP`

#### 1.1.3 Skeleton

ğŸ—“ï¸ **2019**

- ğŸ“„ [MPED-RNN](https://openaccess.thecvf.com/content_CVPR_2019/html/Morais_Learning_Regularity_in_Skeleton_Trajectories_for_Anomaly_Detection_in_Videos_CVPR_2019_paper.html):Learning regularity in skeleton trajectories for anomaly detection in videos, ğŸ“° `CVPR`  [code](https://github.com/RomeroBarata/skeleton_based_anomaly_detection)

ğŸ—“ï¸ **2020**

- ğŸ“„ [GEPC](https://openaccess.thecvf.com/content_CVPR_2020/html/Markovitz_Graph_Embedded_Pose_Clustering_for_Anomaly_Detection_CVPR_2020_paper.html):Graph embedded pose clustering for anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/amirmk89/gepc)

- ğŸ“„ [MTTP](https://openaccess.thecvf.com/content_WACV_2020/html/Rodrigues_Multi-timescale_Trajectory_Prediction_for_Abnormal_Human_Activity_Detection_WACV_2020_paper.html):Multi-timescale trajectory prediction for abnormal human activity detection, ğŸ“° `WACV`   [homepage](https://github.com/Rodrigues-Royston/Multi-timescale-Trajectory-Prediction-for-Abnormal-Human-Activity-Detection/tree/master)

ğŸ—“ï¸ **2021**

- ğŸ“„ [NormalGraph](https://www.sciencedirect.com/science/article/abs/pii/S0925231220317720):Normal graph: Spatial temporal graph convolutional networks based prediction network for skeleton based video anomaly detection, ğŸ“° `Neurocomputing`

- ğŸ“„ [HSTGCNN](https://ieeexplore.ieee.org/abstract/document/9645572):A hierarchical spatio-temporal graph convolutional neural network for anomaly detection in videos, ğŸ“° `TCSVT`  [code](codeï¼šhttps://github.com/DivineZeng/A-Hierarchical-Spatio-Temporal-Graph-Convolutional-Neural-Network-for-Anomaly-Detection-in-Videos)

ğŸ—“ï¸ **2022**

- ğŸ“„ [TSIF](https://ieeexplore.ieee.org/abstract/document/9746420):A two-stream information fusion approach to abnormal event detection in video, ğŸ“° `ICASSP`

- ğŸ“„ [STGCAE-LSTM](https://www.sciencedirect.com/science/article/abs/pii/S0925231221018373):Human-related anomalous event detection via spatial-temporal graph convolutional autoencoder with embedded long short-term memory network, ğŸ“° `Neurocomputing`

- ğŸ“„ [STGformer](https://dl.acm.org/doi/abs/10.1145/3503161.3548369):Hierarchical graph embedded pose regularity learning via spatiotemporal transformer for abnormal behavior detection, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2023**

- ğŸ“„ [STG-NF](https://openaccess.thecvf.com/content/ICCV2023/html/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.html):Normalizing flows for human pose anomaly detection, ğŸ“° `ICCV` [code](codeï¼šhttps://github.com/orhir/STG-NF)

- ğŸ“„ [MoPRL](https://ieeexplore.ieee.org/abstract/document/10185076):Regularity learning via explicit distribution modeling for skeletal video anomaly detection, ğŸ“° `TCSVT`

- ğŸ“„ [MoCoDAD](https://openaccess.thecvf.com/content/ICCV2023/html/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.html):Multimodal motion conditioned diffusion model for skeleton-based video anomaly detection, ğŸ“° `ICCV`  [code](https://github.com/aleflabo/MoCoDAD)

ğŸ—“ï¸ **2024**

- ğŸ“„ [TrajREC](https://openaccess.thecvf.com/content/WACV2024/html/Stergiou_Holistic_Representation_Learning_for_Multitask_Trajectory_Anomaly_Detection_WACV_2024_paper.html):Holistic representation learning for multitask trajectory anomaly detection, ğŸ“° `WACV`

#### 1.1.4 Hybrid

ğŸ—“ï¸ **2018**

- ğŸ“„ [FuturePred](https://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html):Future frame prediction for anomaly detectionâ€“a new baseline, ğŸ“° `CVPR`  [code](codeï¼šhttps://github.com/StevenLiuWen/ano_pred_cvpr2018)

ğŸ—“ï¸ **2019**

- ğŸ“„ [DeepOC](https://ieeexplore.ieee.org/abstract/document/8825555):A deep one-class neural network for anomalous event detection in complex scenes, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2021**

- ğŸ“„ [HF$^2$-VAD](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Hybrid_Video_Anomaly_Detection_Framework_via_Memory-Augmented_Flow_Reconstruction_ICCV_2021_paper):A hybrid video anomaly detection framework via memory-augmented flow reconstruction and flow-guided frame prediction, ğŸ“° `ICCV` [code](https://github.com/LiUzHiAn/hf2vad)

ğŸ—“ï¸ **2024**

- ğŸ“„ [EOGT](https://dl.acm.org/doi/abs/10.1145/3662185):Eogt: Video anomaly detection with enhanced object information and global temporal dependency, ğŸ“° `TOMM`

### 1.2 Methodology

#### 1.2.1 Self-Supervised Learning

**Reconstruction**

ğŸ—“ï¸ **2016**

- ğŸ“„ [ConvAE](https://openaccess.thecvf.com/content_cvpr_2016/html/Hasan_Learning_Temporal_Regularity_CVPR_2016_paper.html):Learning temporal regularity in video sequences, ğŸ“° `CVPR` [code](https://github.com/mhasa004/caffe) [homepage](https://mhasa004.github.io/regularity.html)

ğŸ—“ï¸ **2017**

- ğŸ“„ [ConvLSTM-AE](https://ieeexplore.ieee.org/abstract/document/8019325/):Remembering history with convolutional LSTM for anomaly detection, ğŸ“° `ICCV` [code](https://github.com/zachluo/convlstm_anomaly_detection)

ğŸ—“ï¸ **2018**

- ğŸ“„ [FuturePred](https://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html):Future frame prediction for anomaly detectionâ€“a new baseline, ğŸ“° `CVPR`  [code](https://github.com/StevenLiuWen/ano_pred_cvpr2018)

- ğŸ“„ [S$^2$-VAE](https://ieeexplore.ieee.org/abstract/document/8513816):Generative neural networks for anomaly detection in crowded scenes, ğŸ“° `TIFS`

ğŸ—“ï¸ **2019**

- ğŸ“„ [AMC](https://openaccess.thecvf.com/content_ICCV_2019/html/Nguyen_Anomaly_Detection_in_Video_Sequence_With_Appearance-Motion_Correspondence_ICCV_2019_paper.html): Anomaly detection in video sequence with appearance-motion correspondence, ğŸ“° `ICCV`  [code](https://github.com/nguyetn89/Anomaly_detection_ICCV2019)

ğŸ—“ï¸ **2020**

- ğŸ“„ [ClusterAE](https://link.springer.com/chapter/10.1007/978-3-030-58555-6_20):Clustering driven deep autoencoder for video anomaly detection, ğŸ“° `ECCV`

- ğŸ“„ [SIGnet](https://ieeexplore.ieee.org/abstract/document/9288937):Anomaly detection with bidirectional consistency in videos, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2021**

- ğŸ“„ [SSR-AE](https://ieeexplore.ieee.org/abstract/document/9632460):Self-supervision-augmented deep autoencoder for unsupervised visual anomaly detection, ğŸ“° `TCYB`

ğŸ—“ï¸ **2023**

- ğŸ“„ [MoPRL](https://ieeexplore.ieee.org/abstract/document/10185076):Regularity learning via explicit distribution modeling for skeletal video anomaly detection, ğŸ“° `TCSVT`

**Prediction**

ğŸ—“ï¸ **2019**

- ğŸ“„ [Attention-driven-loss](https://ieeexplore.ieee.org/abstract/document/8943099):Attention-driven loss for anomaly detection in video surveillance, ğŸ“° `TCSVT`  [code](codeï¼šhttps://github.com/joeyzhouty/Attention-driven-loss)

ğŸ—“ï¸ **2020**

- ğŸ“„ [Multispace](https://ieeexplore.ieee.org/abstract/document/9266126):Normality learning in multispace for video anomaly detection, ğŸ“° `TCSVT`

ğŸ—“ï¸ **2021**

- ğŸ“„ [HF$^2$-VAD](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Hybrid_Video_Anomaly_Detection_Framework_via_Memory-Augmented_Flow_Reconstruction_ICCV_2021_paper):A hybrid video anomaly detection framework via memory-augmented flow reconstruction and flow-guided frame prediction, ğŸ“° `ICCV` [code](https://github.com/LiUzHiAn/hf2vad)

- ğŸ“„ [AMMC-Net](https://ojs.aaai.org/index.php/AAAI/article/view/16177):Appearance-motion memory consistency network for video anomaly detection, ğŸ“° `AAAI`  [code](https://github.com/NjuHaoZhang/AMMCNet_AAAI2021)

- ğŸ“„ [ROADMAP](https://ieeexplore.ieee.org/abstract/document/9446996):Robust unsupervised video anomaly detection by multipath frame prediction, ğŸ“° `TNNLS`

- ğŸ“„ [AEP](https://ieeexplore.ieee.org/abstract/document/9346050):Abnormal event detection and localization via adversarial event prediction, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2022**

- ğŸ“„ [STGformer](https://dl.acm.org/doi/abs/10.1145/3503161.3548369):Hierarchical graph embedded pose regularity learning via spatiotemporal transformer for abnormal behavior detection, ğŸ“° `ACM MM`

- ğŸ“„ [OGMRA](https://ieeexplore.ieee.org/abstract/document/9859927):Object-guided and motion-refined attention network for video anomaly detection, ğŸ“° `ICME`

ğŸ—“ï¸ **2023**

- ğŸ“„ [STGCN](https://ieeexplore.ieee.org/abstract/document/10095170):Spatial-temporal graph convolutional network boosted flow-frame prediction for video anomaly detection, ğŸ“° `ICASSP`

- ğŸ“„ [AMP-NET](https://ieeexplore.ieee.org/abstract/document/10203018):Amp-net: Appearance-motion prototype network assisted automatic video anomaly detection system, ğŸ“° `TII`

**Visual Cloze Test**

ğŸ—“ï¸ **2020**

- ğŸ“„ [VEC](https://dl.acm.org/doi/abs/10.1145/3394171.3413973):Cloze test helps: Effective video anomaly detection via learning to complete video events, ğŸ“° `ACM MM`  [code](https://github.com/yuguangnudt/VEC_VAD)

ğŸ—“ï¸ **2023**

- ğŸ“„ [USTN-DSC](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Video_Event_Restoration_Based_on_Keyframes_for_Video_Anomaly_Detection_CVPR_2023_paper.html):Video event restoration based on keyframes for video anomaly detection, ğŸ“° `CVPR`

- ğŸ“„ [VCC](https://ieeexplore.ieee.org/abstract/document/10197574):Video anomaly detection via visual cloze tests, ğŸ“° `TIFS`

**Jigsaw Puzzles**

ğŸ—“ï¸ **2022**

- ğŸ“„ [STJP](https://link.springer.com/chapter/10.1007/978-3-031-20080-9_29):Video anomaly detection by solving decoupled spatio-temporal jigsaw puzzles, ğŸ“° `ECCV`  [code](https://github.com/gdwang08/Jigsaw-VAD)

ğŸ—“ï¸ **2023**

- ğŸ“„ [MPT](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.html):Video anomaly detection via sequentially learning multiple pretext tasks, ğŸ“° `ICCV`

- ğŸ“„ [SSMTL++](https://www.sciencedirect.com/science/article/abs/pii/S107731422300036X):Ssmtl++: Revisiting self-supervised multi-task learning for video anomaly detection, ğŸ“° `CVIU`

**Contrastive Learning**

ğŸ—“ï¸ **2020**

- ğŸ“„ [CAC](https://dl.acm.org/doi/abs/10.1145/3394171.3413529):Cluster attention contrast for video anomaly detection, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2021**

- ğŸ“„ [TAC-Net](https://ieeexplore.ieee.org/abstract/document/9591368):Abnormal event detection using deep contrastive learning for intelligent video surveillance system, ğŸ“° `TII`

ğŸ—“ï¸ **2022**

- ğŸ“„ [LSH](https://ieeexplore.ieee.org/abstract/document/9882128):Learnable locality-sensitive hashing for video anomaly detection, ğŸ“° `TCSVT`

**Denoising**

ğŸ—“ï¸ **2020**

- ğŸ“„ [Adv-AE](https://ieeexplore.ieee.org/abstract/document/9194323):Adversarial 3d convolutional autoencoder for abnormal event detection in videos, ğŸ“° `TMM`

ğŸ—“ï¸ **2021**

- ğŸ“„ [NM-GAN](https://www.sciencedirect.com/science/article/abs/pii/S0031320321001564):Nm-gan: Noise-modulated generative adversarial network for video anomaly detection, ğŸ“° `PR`

**Deep Sparse Coding**

ğŸ—“ï¸ **2017**

- ğŸ“„ [Stacked-RNN](https://openaccess.thecvf.com/content_iccv_2017/html/Luo_A_Revisit_of_ICCV_2017_paper.html), A revisit of sparse coding based anomaly detection in stacked RNN frameworkğŸ“° `ICCV` [code](https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection)

ğŸ—“ï¸ **2019**

- ğŸ“„ [Anomalynet](https://ieeexplore.ieee.org/abstract/document/8649753):Anomalynet: An anomaly detection network for video surveillance, ğŸ“° `TIFS` [code](https://github.com/joeyzhouty/AnomalyNet)

- ğŸ“„ [sRNN-AE](https://ieeexplore.ieee.org/abstract/document/8851288):Video anomaly detection with sparse coding inspired deep neural networks, ğŸ“° `TPAMI` [code](https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection)

ğŸ—“ï¸ **2020**

- ğŸ“„ [FSCN](https://www.sciencedirect.com/science/article/abs/pii/S0031320320303186):Fast sparse coding networks for anomaly detection in videos, ğŸ“° `PR` [code](https://github.com/Roc-Ng/FSCN_AnomalyDetection)

**Patch Inpainting**

ğŸ—“ï¸ **2021**

- ğŸ“„ [RIAD](https://www.sciencedirect.com/science/article/abs/pii/S0031320320305094):Reconstruction by inpainting for visual anomaly detection, ğŸ“° `PR`  [code](https://github.com/plutoyuxie/Reconstruction-by-inpainting-for-visual-anomaly-detection)

ğŸ—“ï¸ **2022**

- ğŸ“„ [SSPCAB](https://openaccess.thecvf.com/content/CVPR2022/html/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.html):Self-supervised predictive convolutional attentive block for anomaly detection, ğŸ“° `CVPR` [code](https://github.com/ristea/sspcab)

ğŸ—“ï¸ **2023**

- ğŸ“„ [SSMCTB](https://ieeexplore.ieee.org/abstract/document/10273635):Self-supervised masked convolutional transformer block for anomaly detection, ğŸ“° `TPAMI`  [code](https://github.com/ristea/ssmctb)

ğŸ—“ï¸ **2024**

- ğŸ“„ [AED-MAE](https://openaccess.thecvf.com/content/CVPR2024/html/Ristea_Self-Distilled_Masked_Auto-Encoders_are_Efficient_Video_Anomaly_Detectors_CVPR_2024_paper.html):Self-distilled masked auto-encoders are efficient video anomaly detectors, ğŸ“° `CVPR` [code](https://github.com/ristea/aed-mae)

**Multiple Task**

ğŸ—“ï¸ **2017**

- ğŸ“„ [STAE](https://dl.acm.org/doi/abs/10.1145/3123266.3123451): Spatio-temporal autoencoder for video anomaly detection, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2019**

- ğŸ“„ [MPED-RNN](https://openaccess.thecvf.com/content_CVPR_2019/html/Morais_Learning_Regularity_in_Skeleton_Trajectories_for_Anomaly_Detection_in_Videos_CVPR_2019_paper.html):Learning regularity in skeleton trajectories for anomaly detection in videos, ğŸ“° `CVPR`

- ğŸ“„ [AnoPCN](https://dl.acm.org/doi/abs/10.1145/3343031.3350899):Anopcn: Video anomaly detection via deep predictive coding network, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2021**

- ğŸ“„ [Multitask](https://openaccess.thecvf.com/content/CVPR2021/html/Georgescu_Anomaly_Detection_in_Video_via_Self-Supervised_and_Multi-Task_Learning_CVPR_2021_paper.html):Anomaly detection in video via self-supervised and multi-task learning, ğŸ“° `CVPR`   [homepage](https://github.com/lilygeorgescu/AED-SSMTL)

ğŸ—“ï¸ **2022**

- ğŸ“„ [HSNBM](https://dl.acm.org/doi/abs/10.1145/3503161.3548199):Hierarchical scene normality-binding modeling for anomaly detection in surveillance videos, ğŸ“° `ACM MM` [code](https://github.com/baoqianyue/HSNBM)

- ğŸ“„ [LSH](https://ieeexplore.ieee.org/abstract/document/9882128):Learnable locality-sensitive hashing for video anomaly detection, ğŸ“° `TCSVT`

- ğŸ“„ [AMAE](https://ieeexplore.ieee.org/abstract/document/9739751):Appearance-motion united auto-encoder framework for video anomaly detection, ğŸ“° `TCAS-II`

- ğŸ“„ [STM-AE](https://ieeexplore.ieee.org/abstract/document/9859727):Learning appearance-motion normality for video anomaly detection, ğŸ“° `ICME`

- ğŸ“„ [SSAGAN](https://ieeexplore.ieee.org/abstract/document/9749781):Self-supervised attentive generative adversarial networks for video anomaly detection, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2023**

- ğŸ“„ [MPT](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.html):Video anomaly detection via sequentially learning multiple pretext tasks, ğŸ“° `ICCV`

- ğŸ“„ [SSMTL++](https://www.sciencedirect.com/science/article/abs/pii/S107731422300036X):Ssmtl++: Revisiting self-supervised multi-task learning for video anomaly detection, ğŸ“° `CVIU`

ğŸ—“ï¸ **2024**

- ğŸ“„ [MGSTRL](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Multi-Scale_Video_Anomaly_Detection_by_Multi-Grained_Spatio-Temporal_Representation_Learning_CVPR_2024_paper.html):Multi-scale video anomaly detection by multi-grained spatiotemporal representation learning, ğŸ“° `CVPR`

#### 1.2.2 One-Class Learning

**One-Class Classifier**

ğŸ—“ï¸ **2015**

- ğŸ“„ [AMDN](https://arxiv.org/abs/1510.01553):Learning deep representations of appearance and motion for anomalous event detection, ğŸ“° `BMVC`

ğŸ—“ï¸ **2018**

- ğŸ“„ [Deep SVDD](https://proceedings.mlr.press/v80/ruff18a.html):Deep one-class classification, ğŸ“° `PMLR`  [code](https://github.com/lukasruff/Deep-SVDD-PyTorch)

ğŸ—“ï¸ **2019**

- ğŸ“„ [DeepOC](https://ieeexplore.ieee.org/abstract/document/8825555):A deep one-class neural network for anomalous event detection in complex scenes, ğŸ“° `TNNLS`
- ğŸ“„ [GODS](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008531):Gods: Generalized one-class discriminative subspaces for anomaly detection,  ğŸ“° `ICCV`

ğŸ—“ï¸ **2021**

- ğŸ“„ [FCDD](https://openreview.net/forum?id=A5VV3UyIQz):Explainable deep one-class classification, ğŸ“° `ICLR`  [code](https://github.com/liznerski/fcdd)

**Gaussian Classifier**

ğŸ—“ï¸ **2018**

- ğŸ“„ [Deep-anomaly](https://www.sciencedirect.com/science/article/abs/pii/S1077314218300249):Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes, ğŸ“° `CVIU`

ğŸ—“ï¸ **2020**

- ğŸ“„ [GM-VAE](https://www.sciencedirect.com/science/article/abs/pii/S1077314218302674):Video anomaly detection and localization via gaussian mixture fully convolutional variational autoencoder, ğŸ“° `CVIU`

ğŸ—“ï¸ **2021**

- ğŸ“„ [Deep-cascade](https://ieeexplore.ieee.org/abstract/document/7858798):Deep-cascade: Cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes, ğŸ“° `TIP`

**Adversarial Classifier**

ğŸ—“ï¸ **2018**

- ğŸ“„ [ALOCC](https://openaccess.thecvf.com/content_cvpr_2018/html/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.html):Adversarially learned one-class classifier for novelty detection, ğŸ“° `CVPR`  [code](https://github.com/khalooei/ALOCC-CVPR2018)

- ğŸ“„ [AVID](https://link.springer.com/chapter/10.1007/978-3-030-20876-9_31):Avid: Adversarial visual irregularity detection, ğŸ“° `ACCV` [code](https://github.com/cross32768/AVID-Adversarial-Visual-Irregularity-Detection/tree/master)

ğŸ—“ï¸ **2020**

- ğŸ“„ [ALOCC2](https://ieeexplore.ieee.org/abstract/document/9059022):Deep end-to-end one-class classifier, ğŸ“° `TNNLS`

- ğŸ“„ [OGNet](https://openaccess.thecvf.com/content_CVPR_2020/html/Zaheer_Old_Is_Gold_Redefining_the_Adversarially_Learned_One-Class_Classifier_Training_CVPR_2020_paper.html):Old is gold: Redefining the adversarially learned one-class classifier training paradigm, ğŸ“° `CVPR`  [code](https://github.com/xaggi/OGNet)

ğŸ—“ï¸ **2022**

- ğŸ“„ [OGNet+](https://ieeexplore.ieee.org/abstract/document/9887825):Stabilizing adversarially learned one-class novelty detection using pseudo anomalies, ğŸ“° `TIP`

#### 1.2.3 Interpretable Learning

ğŸ—“ï¸ **2017**

- ğŸ“„ [FRCN](https://openaccess.thecvf.com/content_iccv_2017/html/Hinami_Joint_Detection_and_ICCV_2017_paper.html):Joint detection and recounting of abnormal events by learning deep generic knowledge, ğŸ“° `ICCV`

ğŸ—“ï¸ **2022**

- ğŸ“„ [Accurate-Interpretable-VAD](https://arxiv.org/abs/2212.00789):Attribute-based representations for accurate and interpretable video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/talreiss/Accurate-Interpretable-VAD)

ğŸ—“ï¸ **2023**

- ğŸ“„ [InterVAD](https://openaccess.thecvf.com/content/WACV2023/html/Doshi_Towards_Interpretable_Video_Anomaly_Detection_WACV_2023_paper.html):Towards interpretable video anomaly detection, ğŸ“° `WACV`

- ğŸ“„ [EVAL](https://openaccess.thecvf.com/content/CVPR2023/html/Singh_EVAL_Explainable_Video_Anomaly_Localization_CVPR_2023_paper.html):Eval: Explainable video anomaly localization, ğŸ“° `CVPR`

ğŸ—“ï¸ **2024**

- ğŸ“„ [AnomalyRuler](https://openaccess.thecvf.com/content/CVPR2023/html/Singh_EVAL_Explainable_Video_Anomaly_Localization_CVPR_2023_paper.html):Follow the rules: Reasoning for video anomaly detection with large language models, ğŸ“° `ECCV` [code](https://github.com/Yuchen413/AnomalyRuler)

### 1.3 Network Architecture

#### 1.3.1 Auto-Encoder

ğŸ—“ï¸ **2016**

- ğŸ“„ [Conv-LSTM](https://arxiv.org/abs/1612.00390):Anomaly detection in video using predictive convolutional long short-term memory networks, ğŸ“° `Arxiv`

ğŸ—“ï¸ **2017**

- ğŸ“„ [STAE](https://dl.acm.org/doi/abs/10.1145/3123266.3123451): Spatio-temporal autoencoder for video anomaly detection, ğŸ“° `ACM MM`

- ğŸ“„ [ConvLSTM-AE](https://ieeexplore.ieee.org/abstract/document/8019325/):Remembering history with convolutional LSTM for anomaly detection, ğŸ“° `ICCV` [code](https://github.com/zachluo/convlstm_anomaly_detection)

ğŸ—“ï¸ **2019**

- ğŸ“„ [DeepOC](https://ieeexplore.ieee.org/abstract/document/8825555):A deep one-class neural network for anomalous event detection in complex scenes, ğŸ“° `TNNLS`

- ğŸ“„ [sRNN-AE](https://ieeexplore.ieee.org/abstract/document/8851288):Video anomaly detection with sparse coding inspired deep neural networks, ğŸ“° `TPAMI`

- ğŸ“„ [MPED-RNN](https://openaccess.thecvf.com/content_CVPR_2019/html/Morais_Learning_Regularity_in_Skeleton_Trajectories_for_Anomaly_Detection_in_Videos_CVPR_2019_paper.html):Learning regularity in skeleton trajectories for anomaly detection in videos, ğŸ“° `CVPR`

ğŸ—“ï¸ **2021**

- ğŸ“„ [NormalGraph](https://www.sciencedirect.com/science/article/abs/pii/S0925231220317720):Normal graph: Spatial temporal graph convolutional networks based prediction network for skeleton based video anomaly detection, ğŸ“° `Neurocomputing`

ğŸ—“ï¸ **2022**

- ğŸ“„ [STGCAE-LSTM](https://www.sciencedirect.com/science/article/abs/pii/S0925231221018373):Human-related anomalous event detection via spatial-temporal graph convolutional autoencoder with embedded long short-term memory network, ğŸ“° `Neurocomputing`

ğŸ—“ï¸ **2023**

- ğŸ“„ [USTN-DSC](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Video_Event_Restoration_Based_on_Keyframes_for_Video_Anomaly_Detection_CVPR_2023_paper.html):Video event restoration based on keyframes for video anomaly detection, ğŸ“° `CVPR`

ğŸ—“ï¸ **2024**

- ğŸ“„ [AED-MAE](https://openaccess.thecvf.com/content/CVPR2024/html/Ristea_Self-Distilled_Masked_Auto-Encoders_are_Efficient_Video_Anomaly_Detectors_CVPR_2024_paper.html):Self-distilled masked auto-encoders are efficient video anomaly detectors, ğŸ“° `CVPR`  [code](https://github.com/ristea/aed-mae)

#### 1.3.2 GAN

ğŸ—“ï¸ **2018**

- ğŸ“„ [FuturePred](https://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html):Future frame prediction for anomaly detectionâ€“a new baseline, ğŸ“° `CVPR`  [code](https://github.com/StevenLiuWen/ano_pred_cvpr2018)
- ğŸ“„ [ALOCC](https://openaccess.thecvf.com/content_cvpr_2018/html/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.html):Adversarially learned one-class classifier for novelty detection, ğŸ“° `CVPR`  [code](https://github.com/khalooei/ALOCC-CVPR2018)

ğŸ—“ï¸ **2019**

- ğŸ“„ [AD-VAD](https://ieeexplore.ieee.org/abstract/document/8658774):Training adversarial discriminators for cross-channel abnormal event detection in crowds, ğŸ“° `WACV`

- ğŸ“„ [VAD-GAN](https://ojs.aaai.org/index.php/AAAI/article/view/4456):Robust anomaly detection in videos using multilevel representations, ğŸ“° `AAAI`  [code](https://github.com/SeaOtter/vad_gan)

- ğŸ“„ [Ada-Net](https://ieeexplore.ieee.org/abstract/document/8892741):Learning normal patterns via adversarial attention-based autoencoder for abnormal event detection in videos, ğŸ“° `TMM`

- 

ğŸ—“ï¸ **2020**

- ğŸ“„ [OGNet](https://openaccess.thecvf.com/content_CVPR_2020/html/Zaheer_Old_Is_Gold_Redefining_the_Adversarially_Learned_One-Class_Classifier_Training_CVPR_2020_paper.html):Old is gold: Redefining the adversarially learned one-class classifier training paradigm, ğŸ“° `CVPR`  [code](https://github.com/xaggi/OGNet)

ğŸ—“ï¸ **2021**

- ğŸ“„ [CT-D2GAN](https://dl.acm.org/doi/abs/10.1145/3474085.3475693):Convolutional transformer based dual discriminator generative adversarial networks for video anomaly detection, ğŸ“° `ACM MM`

#### 1.3.3 Diffusion

ğŸ—“ï¸ **2023**

- ğŸ“„ [FPDM](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.html):Feature prediction diffusion model for video anomaly detection, ğŸ“° `ICCV`

- ğŸ“„ [MoCoDAD](https://openaccess.thecvf.com/content/ICCV2023/html/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.html):Multimodal motion conditioned diffusion model for skeleton-based video anomaly detection, ğŸ“° `ICCV`  [code](https://github.com/aleflabo/MoCoDAD)

### 1.4 Model Refinement

#### 1.4.1 Pseudo Anomalies

ğŸ—“ï¸ **2021**

- ğŸ“„ [LNRA](https://arxiv.org/abs/2110.09742):Learning not to reconstruct anomalies, ğŸ“° `BMVC` [code](https://github.com/aseuteurideu/LearningNotToReconstructAnomalies)

- ğŸ“„ [G2D](https://openaccess.thecvf.com/content/WACV2021/html/Pourreza_G2D_Generate_to_Detect_Anomaly_WACV_2021_paper.html):G2d: Generate to detect anomaly, ğŸ“° `WACV`  [code](https://github.com/masoudpz/G2D_generate_to_detect_anomaly)

- ğŸ“„ [BAF](https://ieeexplore.ieee.org/abstract/document/9410375):A background-agnostic framework with adversarial training for abnormal event detection in video, ğŸ“° `TPAMI` [code](https://github.com/lilygeorgescu/AED)

ğŸ—“ï¸ **2022**

- ğŸ“„ [OGNet+](https://ieeexplore.ieee.org/abstract/document/9887825):Stabilizing adversarially learned one-class novelty detection using pseudo anomalies, ğŸ“° `TIP`

- ğŸ“„ [MBPA](https://ieeexplore.ieee.org/abstract/document/9826251):Limiting reconstruction capability of autoencoders using moving backward pseudo anomalies, ğŸ“° `UR`

ğŸ—“ï¸ **2023**

- ğŸ“„ [DSS-NET](https://ieeexplore.ieee.org/abstract/document/10174739):Dss-net: Dynamic self-supervised network for video anomaly detection, ğŸ“° `TMM` 

- ğŸ“„ [PseudoBound](https://www.sciencedirect.com/science/article/pii/S092523122300228X):Pseudobound: Limiting the anomaly reconstruction capability of one-class classifiers using pseudo anomalies, ğŸ“° `Neurocomputing`

- ğŸ“„ [PFMF](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Generating_Anomalies_for_Video_Anomaly_Detection_With_Prompt-Based_Feature_Mapping_CVPR_2023_paper.html):Generating anomalies for video anomaly detection with prompt-based feature mapping, ğŸ“° `CVPR`

#### 1.4.2 Memory Bank

ğŸ—“ï¸ **2019**

- ğŸ“„ [MemAE](https://openaccess.thecvf.com/content_ICCV_2019/html/Gong_Memorizing_Normality_to_Detect_Anomaly_Memory-Augmented_Deep_Autoencoder_for_Unsupervised_ICCV_2019_paper.html): Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection, ğŸ“° `ICCV` [code](https://github.com/donggong1/memae-anomaly-detection)

ğŸ—“ï¸ **2020**

- ğŸ“„ [MNAD](https://openaccess.thecvf.com/content_CVPR_2020/html/Park_Learning_Memory-Guided_Normality_for_Anomaly_Detection_CVPR_2020_paper.html\):Learning memory-guided normality for anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/cvlab-yonsei/MNAD)  [homepage](https://cvlab.yonsei.ac.kr/projects/MNAD/)

ğŸ—“ï¸ **2021**

- ğŸ“„ [MPN](https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Learning_Normal_Dynamics_in_Videos_With_Meta_Prototype_Network_CVPR_2021_paper.html):Learning normal dynamics in videos with meta prototype network, ğŸ“° `CVPR`  [code](https://github.com/ktr-hubrt/MPN)

ğŸ—“ï¸ **2022**

- ğŸ“„ [EPAP-Net](https://dl.acm.org/doi/abs/10.1145/3503161.3548000):Anomaly warning: Learning and memorizing future semantic patterns for unsupervised ex-ante potential anomaly prediction, ğŸ“° `ACM MM`

- ğŸ“„ [CAFE](https://dl.acm.org/doi/abs/10.1145/3503161.3547944):Effective video abnormal event detection by learning a consistency-aware high-level feature extractor, ğŸ“° `ACM MM`

- ğŸ“„ [DLAN-AC](https://link.springer.com/chapter/10.1007/978-3-031-19772-7_24):Dynamic local aggregation network with adaptive clusterer for anomaly detection, ğŸ“° `ECCV`  [code](https://github.com/Beyond-Zw/DLAN-AC)

ğŸ—“ï¸ **2023**

- ğŸ“„ [DMAD](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Diversity-Measurable_Anomaly_Detection_CVPR_2023_paper.html):Diversity-measurable anomaly detection, ğŸ“° `CVPR` [code](https://github.com/FlappyPeggy/DMAD)

- ğŸ“„ [SVN](https://www.sciencedirect.com/science/article/abs/pii/S0950705123007360):Stochastic video normality network for abnormal event detection in surveillance videos, ğŸ“° `KBS`

- ğŸ“„ [LERF](https://ojs.aaai.org/index.php/AAAI/article/view/25334):Learning event-relevant factors for video anomaly detection, ğŸ“° `AAAI`

- ğŸ“„ [MAAM-Net](https://www.sciencedirect.com/science/article/abs/pii/S0031320323000365):Memory-augmented appearance-motion network for video anomaly detection, ğŸ“° `PR`

ğŸ—“ï¸ **2024**

- ğŸ“„ [STU-Net](https://ieeexplore.ieee.org/abstract/document/10462921):Context recovery and knowledge retrieval: A novel two-stream framework for video anomaly detection, ğŸ“° `TIP`  [homepage](https://github.com/zugexiaodui/TwoStreamUVAD)

### 1.5 Model Output

#### 1.5.1 Frame Level

#### 1.5.2 Pixel Level

ğŸ—“ï¸ **2022**

- ğŸ“„ [UPformer](https://dl.acm.org/doi/abs/10.1145/3503161.3548082):Pixel-level anomaly detection via uncertainty-aware prototypical transformer, ğŸ“° `ACM MM`

## 2. Weakly Supervised Video Anomaly Detection

ğŸ—“ï¸ **2018**

- ğŸ“„ [DeepMIL](https://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html): Real-world anomaly detectionin surveillance videos, ğŸ“° `CVPR` [code](https://github.com/WaqasSultani/AnomalyDetectionCVPR2018)[homepage](http://crcv.ucf.edu/projects/real-world/)

### 2.1 Model Input

#### 2.1.1 RGB

ğŸ—“ï¸ **2018**

- ğŸ“„ [DeepMIL](https://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html): Real-world anomaly detectionin surveillance videos, ğŸ“° `CVPR` [code1](https://github.com/WaqasSultani/AnomalyDetectionCVPR2018) [code2](https://github.com/Roc-Ng/DeepMIL)  [homepage](http://crcv.ucf.edu/projects/real-world/)

ğŸ—“ï¸ **2019**

- ğŸ“„ [GCN](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Graph_Convolutional_Label_Noise_Cleaner_Train_a_Plug-And-Play_Action_Classifier_CVPR_2019_paper.html):Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/jx-zhong-for-academic-purpose/GCN-Anomaly-Detection)

ğŸ—“ï¸ **2020**

- ğŸ“„ [CLAWS](https://link.springer.com/chapter/10.1007/978-3-030-58542-6_22): Claws: Clustering assisted weakly supervised learning with normalcy suppression for anomalous event detection, ğŸ“° `ECCV`  [code](https://github.com/xaggi/claws_eccv)

- ğŸ“„ [HLNet](https://link.springer.com/chapter/10.1007/978-3-030-58577-8_20):Not only look, but also listen: Learning multimodal violence detection under weak supervision, ğŸ“° `ECCV`  [code](https://github.com/Roc-Ng/XDVioDet) [homepage](https://roc-ng.github.io/XD-Violence/)

ğŸ—“ï¸ **2022**

- ğŸ“„ [S3R](https://link.springer.com/chapter/10.1007/978-3-031-19778-9_42):Self-supervised sparse representation for video anomaly detection, ğŸ“° `ECCV`  [code](https://github.com/louisYen/S3R)

- ğŸ“„ [GCN+](https://www.sciencedirect.com/science/article/abs/pii/S0925231222000443):Weakly-supervised anomaly detection in video surveillance via graph convolutional label noise cleaning, ğŸ“° `Neurocomputing`

- ğŸ“„ [MSL](https://ojs.aaai.org/index.php/AAAI/article/view/20028):Self-training multi-sequence learning with transformer for weakly supervised video anomaly detection, ğŸ“° `AAAI`

ğŸ—“ï¸ **2023**

- ğŸ“„ [BN-WVAD](https://arxiv.org/abs/2311.15367):Batchnorm-based weakly supervised video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/cool-xuan/BN-WVAD)

- ğŸ“„ [LSTC](https://ieeexplore.ieee.org/abstract/document/10219868):Long-short temporal co-teaching for weakly supervised video anomaly detection, ğŸ“° `ICME`  [code](https://github.com/shengyangsun/LSTC_VAD)

ğŸ—“ï¸ **2024**

- ğŸ“„ [AlMarri Salem et al.](https://openaccess.thecvf.com/content/WACV2024W/RWS/html/AlMarri_A_Multi-Head_Approach_With_Shuffled_Segments_for_Weakly-Supervised_Video_Anomaly_WACVW_2024_paper.html): A multi-head approach with shuffled segments for weakly-supervised video anomaly detection, ğŸ“° `WACV`

- ğŸ“„ [OVVAD](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Open-Vocabulary_Video_Anomaly_Detection_CVPR_2024_paper.html):Open-vocabulary video anomaly detection, ğŸ“° `CVPR`

#### 2.1.2 Optical Flow

ğŸ—“ï¸ **2019**

- ğŸ“„ [GCN](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Graph_Convolutional_Label_Noise_Cleaner_Train_a_Plug-And-Play_Action_Classifier_CVPR_2019_paper.html):Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/jx-zhong-for-academic-purpose/GCN-Anomaly-Detection)

ğŸ—“ï¸ **2020**

- ğŸ“„ [AR-NET](https://ieeexplore.ieee.org/abstract/document/9102722):Weakly supervised video anomaly detection via center-guided discriminative learning, ğŸ“° `ICME`  [code](https://github.com/wanboyang/Anomaly_AR_Net_ICME_2020)

#### 2.1.3 Audio

ğŸ—“ï¸ **2021**

- ğŸ“„ [FVAL](https://ieeexplore.ieee.org/abstract/document/9413686):Violence detection in videos based on fusing visual and audio information, ğŸ“° `ICASSP`

ğŸ—“ï¸ **2023**

- ğŸ“„ [HyperVD](https://arxiv.org/abs/2305.18797):Learning weakly supervised audio-visual violence detection in hyperbolic space, ğŸ“° `Arxiv`  [code](https://github.com/xiaogangpeng/HyperVD)

#### 2.1.4 Text

ğŸ—“ï¸ **2023**

- ğŸ“„ [PEL4VAD](https://arxiv.org/abs/2306.14451):Learning prompt-enhanced context features for weakly-supervised video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/yujiangpu20/PEL4VAD)

- ğŸ“„ [TEVAD](https://openaccess.thecvf.com/content/CVPR2023W/O-DRUM/html/Chen_TEVAD_Improved_Video_Anomaly_Detection_With_Captions_CVPRW_2023_paper.html):Tevad: Improved video anomaly detection with captions, ğŸ“° `CVPRW` [code](https://github.com/coranholmes/TEVAD)

ğŸ—“ï¸ **2024**

- ğŸ“„ [LAP](https://arxiv.org/abs/2403.01169):Learn suspected anomalies from event prompts for video anomaly detection, ğŸ“° `Arxiv`

- ğŸ“„ [ALAN](https://ieeexplore.ieee.org/abstract/document/10471334):Toward video anomaly retrieval from video anomaly detection: New benchmarks and model, ğŸ“° `TIP`

#### 2.1.5 Hybrid

ğŸ—“ï¸ **2020**

- ğŸ“„ [AR-NET](https://ieeexplore.ieee.org/abstract/document/9102722):Weakly supervised video anomaly detection via center-guided discriminative learning, ğŸ“° `ICME`  [code](https://github.com/wanboyang/Anomaly_AR_Net_ICME_2020)

ğŸ—“ï¸ **2022**

- ğŸ“„ [ACF_MMVD](https://ieeexplore.ieee.org/abstract/document/9746422):Look, listen and pay more attention: Fusing multi-modal information for video violence detection, ğŸ“° `ICASSP`  [code]( https://github.com/DL-Wei/ACF_MMVD)

- ğŸ“„ [MSFA](https://ieeexplore.ieee.org/abstract/document/9926192):Msaf: Multimodal supervise-attention enhanced fusion for video anomaly detection, ğŸ“° `SPL`  [homepage](https://github.com/Video-AD/MSFA)

- ğŸ“„ [MACIL_SD](https://dl.acm.org/doi/abs/10.1145/3503161.3547868):Modality-aware contrastive instance learning with self-distillation for weakly-supervised audio-visual violence detection, ğŸ“° `ACM MM`  [code](https://github.com/JustinYuu/MACIL_SD)

- ğŸ“„ [HL-Net+](https://ieeexplore.ieee.org/abstract/document/9699377):Weakly supervised audio-visual violence detection, ğŸ“° `TMM`

ğŸ—“ï¸ **2024**

- ğŸ“„ [UCA](https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Towards_Surveillance_Video-and-Language_Understanding_New_Dataset_Baselines_and_Challenges_CVPR_2024_paper.html):Towards surveillance video-and-language understanding: New dataset baselines and challenges, ğŸ“° `CVPR`  [homepage](https://github.com/Xuange923/Surveillance-Video-Understanding)

### 2.2 Methodology

#### 2.2.1 One-Stage MIL

ğŸ—“ï¸ **2018**

- ğŸ“„ [DeepMIL](https://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html): Real-world anomaly detectionin surveillance videos, ğŸ“° `CVPR` [code1](https://github.com/WaqasSultani/AnomalyDetectionCVPR2018) [code2](https://github.com/Roc-Ng/DeepMIL) ([homepage](http://crcv.ucf.edu/projects/real-world/)

ğŸ—“ï¸ **2019**

- ğŸ“„ [MAF](https://arxiv.org/abs/1907.10211):Motion-aware feature for improved video anomaly detection ğŸ“° `BMVC`

- ğŸ“„ [TCN-IBL](https://ieeexplore.ieee.org/abstract/document/8803657):Temporal convolutional network with complementary inner bag loss for weakly supervised anomaly detection, ğŸ“° `ICIP`

ğŸ—“ï¸ **2020**

- ğŸ“„ [HLNet](https://link.springer.com/chapter/10.1007/978-3-030-58577-8_20):Not only look, but also listen: Learning multimodal violence detection under weak supervision, ğŸ“° `ECCV`  [code](https://github.com/Roc-Ng/XDVioDet)

ğŸ—“ï¸ **2022**

- ğŸ“„ [CNL](https://ieeexplore.ieee.org/abstract/document/9739763):Collaborative normality learning framework for weakly supervised video anomaly detection, ğŸ“° ` TCAS-II`

#### 2.2.2 Two-Stage Self-Training

ğŸ—“ï¸ **2019**

- ğŸ“„ [GCN](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Graph_Convolutional_Label_Noise_Cleaner_Train_a_Plug-And-Play_Action_Classifier_CVPR_2019_paper.html):Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection, ğŸ“° `CVPR`

ğŸ—“ï¸ **2021**

- ğŸ“„ [MIST](https://openaccess.thecvf.com/content/CVPR2021/html/Feng_MIST_Multiple_Instance_Self-Training_Framework_for_Video_Anomaly_Detection_CVPR_2021_paper.html):Mist: Multiple instance self-training framework for video anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/fjchange/MIST_VAD)  [homepage](https://kiwi-fung.win/2021/04/28/MIST/)

ğŸ—“ï¸ **2022**

- ğŸ“„ [MSL](https://ojs.aaai.org/index.php/AAAI/article/view/20028):Self-training multi-sequence learning with transformer for weakly supervised video anomaly detection, ğŸ“° `AAAI`

ğŸ—“ï¸ **2023**

- ğŸ“„ [CUPL](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Exploiting_Completeness_and_Uncertainty_of_Pseudo_Labels_for_Weakly_Supervised_CVPR_2023_paper.html):Exploiting completeness and uncertainty of pseudo labels for weakly supervised video anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/ArielZc/CU-Net)

ğŸ—“ï¸ **2024**

- ğŸ“„ [TPWNG](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Text_Prompt_with_Normality_Guidance_for_Weakly_Supervised_Video_Anomaly_CVPR_2024_paper.html):Text prompt with normality guidance for weakly supervised video anomaly detection, ğŸ“° `CVPR`

### 2.3 Refinement Strategy

#### 2.3.1 Temporal Modeling

ğŸ—“ï¸ **2020**

- ğŸ“„ [HLNet](https://link.springer.com/chapter/10.1007/978-3-030-58577-8_20):Not only look, but also listen: Learning multimodal violence detection under weak supervision, ğŸ“° `ECCV`  [code](https://github.com/Roc-Ng/XDVioDet)

ğŸ—“ï¸ **2021**

- ğŸ“„ [CTR](https://ieeexplore.ieee.org/abstract/document/9369126):Learning causal temporal relation and feature discrimination for anomaly detection, ğŸ“° `TIP`

- ğŸ“„ [RTFM](https://openaccess.thecvf.com/content/ICCV2021/html/Tian_Weakly-Supervised_Video_Anomaly_Detection_With_Robust_Temporal_Feature_Magnitude_Learning_ICCV_2021_paper.html):Weakly-supervised video anomaly detection with robust temporal feature magnitude learning, ğŸ“° `ICCV`  [code](https://github.com/tianyu0207/RTFM)

- ğŸ“„ [CA-Net](https://ieeexplore.ieee.org/abstract/document/9540293):Contrastive attention for video anomaly detection, ğŸ“° `TMM`  [code](https://github.com/changsn/Contrastive-Attention-for-Video-Anomaly-Detection)

- ğŸ“„ [CRF](https://openaccess.thecvf.com/content/ICCV2021/html/Purwanto_Dance_With_Self-Attention_A_New_Look_of_Conditional_Random_Fields_ICCV_2021_paper.html):Dance with self-attention: A new look of conditional random fields on anomaly detection in videos, ğŸ“° `ICCV`

ğŸ—“ï¸ **2022**

- ğŸ“„ [MSL](https://ojs.aaai.org/index.php/AAAI/article/view/20028):Self-training multi-sequence learning with transformer for weakly supervised video anomaly detection, ğŸ“° `AAAI`

- ğŸ“„ [DAR](https://ieeexplore.ieee.org/abstract/document/9926133):Decouple and resolve: transformer-based models for online anomaly detection from weakly labeled videos, ğŸ“° `TIFS`

- ğŸ“„ [WAGCN](https://ieeexplore.ieee.org/abstract/document/9968312):Adaptive graph convolutional networks for weakly supervised anomaly detection in videos, ğŸ“° `SPL`

- ğŸ“„ [SGTDT](https://ieeexplore.ieee.org/abstract/document/10002867):Weakly supervised video anomaly detection via self-guided temporal discriminative transformer, ğŸ“° `TCYB`

- ğŸ“„ [MLAD](https://ieeexplore.ieee.org/abstract/document/9774903):Weakly supervised anomaly detection in videos considering the openness of events, ğŸ“° `TITS`

ğŸ—“ï¸ **2023**

- ğŸ“„ [CMRL](https://openaccess.thecvf.com/content/CVPR2023/html/Cho_Look_Around_for_Anomalies_Weakly-Supervised_Anomaly_Detection_via_Context-Motion_Relational_CVPR_2023_paper.html): Look around for anomalies: weakly-supervised anomaly detection via context-motion relational learning, ğŸ“° `CVPR`

- ğŸ“„ [CBCG](https://ieeexplore.ieee.org/abstract/document/10219658):Weakly supervised video anomaly detection based on cross-batch clustering guidance, ğŸ“° `ICME`

- ğŸ“„ [DMU](https://ojs.aaai.org/index.php/AAAI/article/view/25489):Dual memory units with uncertainty regulation for weakly supervised video anomaly detection, ğŸ“° `AAAI`  [code](https://github.com/henrryzh1/UR-DMU)

#### 2.3.2 Spatio-Temporal Modeling

ğŸ—“ï¸ **2022**

- ğŸ“„ [STA-Net](https://ieeexplore.ieee.org/abstract/document/9746822):Learning task-specific representation for video anomaly detection with spatialtemporal attention, ğŸ“° `ICASSP`

- ğŸ“„ [SSRL](https://link.springer.com/chapter/10.1007/978-3-031-19772-7_20):Scale-aware spatio-temporal relation learning for video anomaly detection, ğŸ“° `ECCV`

ğŸ—“ï¸ **2023**

- ğŸ“„ [LSTC](https://ieeexplore.ieee.org/abstract/document/10219868):Long-short temporal co-teaching for weakly supervised video anomaly detection, ğŸ“° `ICME`  [code](https://github.com/shengyangsun/LSTC_VAD)

ğŸ—“ï¸ **2024**

- ğŸ“„ [MSIP](https://ieeexplore.ieee.org/abstract/document/10447603): Learning spatio-temporal relations with multi-scale integrated perception for video anomaly detection, ğŸ“° `ICASSP`

#### 2.3.3 MIL-Based Refinement

ğŸ—“ï¸ **2019**

- ğŸ“„ [Social-MIL](https://ieeexplore.ieee.org/abstract/document/8909882):Social mil: Interaction-aware for crowd anomaly detection, ğŸ“° `AVSS`

ğŸ—“ï¸ **2022**

- ğŸ“„ [MCR](https://ieeexplore.ieee.org/abstract/document/9860012):Multiscale continuity-aware refinement network for weakly supervised video anomaly detection, ğŸ“° `ICME`

- ğŸ“„ [BN-SVP](https://openaccess.thecvf.com/content/CVPR2022/html/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.html):Bayesian nonparametric submodular video partition for robust anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/ritmininglab/BN-SVP)

ğŸ—“ï¸ **2023**

- ğŸ“„ [NGMIL](https://openaccess.thecvf.com/content/WACV2023/html/Park_Normality_Guided_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_WACV_2023_paper.html):Normality guided multiple instance learning for weakly supervised video anomaly detection, ğŸ“° `WACV`

- ğŸ“„ [UMIL](https://openaccess.thecvf.com/content/CVPR2023/html/Lv_Unbiased_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_Detection_CVPR_2023_paper.html):Unbiased multiple instance learning for weakly supervised video anomaly detection, ğŸ“° `CVPR`  [code]( https://github.com/ktr-hubrt/UMIL)

- ğŸ“„ [MGFN](https://ojs.aaai.org/index.php/AAAI/article/view/25112):Mgfn: Magnitude-contrastive glance-and-focus network for weakly-supervised video anomaly detection, ğŸ“° `AAAI`  [code](https://github.com/carolchenyx/MGFN)

ğŸ—“ï¸ **2024**

- ğŸ“„ [LAP](https://arxiv.org/abs/2403.01169):Learn suspected anomalies from event prompts for video anomaly detection, ğŸ“° `Arxiv`

- ğŸ“„ [PE-MIL](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Prompt-Enhanced_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_Detection_CVPR_2024_paper.html): Prompt-enhanced multiple instance learning for weakly supervised video anomaly detection, ğŸ“° `CVPR`

#### 2.3.4 Feature Metric Learning

ğŸ—“ï¸ **2019**

- ğŸ“„ [TCN-IBL](https://ieeexplore.ieee.org/abstract/document/8803657):Temporal convolutional network with complementary inner bag loss for weakly supervised anomaly detection, ğŸ“° `ICIP`

ğŸ—“ï¸ **2021**

- ğŸ“„ [CTR](https://ieeexplore.ieee.org/abstract/document/9369126):Learning causal temporal relation and feature discrimination for anomaly detection, ğŸ“° `TIP`

ğŸ—“ï¸ **2022**

- ğŸ“„ [SGTDT](https://ieeexplore.ieee.org/abstract/document/10002867):Weakly supervised video anomaly detection via self-guided temporal discriminative transformer, ğŸ“° `TCYB`

ğŸ—“ï¸ **2023**

- ğŸ“„ [BN-WVAD](https://arxiv.org/abs/2311.15367):Batchnorm-based weakly supervised video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/cool-xuan/BN-WVAD)

- ğŸ“„ [PEL4VAD](https://arxiv.org/abs/2306.14451):Learning prompt-enhanced context features for weakly-supervised video anomaly detection, ğŸ“° `Arxiv`  [code](https://github.com/yujiangpu20/PEL4VAD)

- ğŸ“„ [TeD-SPAD](https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html):Ted-spad: Temporal distinctiveness for self-supervised privacy-preservation for video anomaly detection, ğŸ“° `ICCV`  [code](https://github.com/UCF-CRCV/TeD-SPAD)

- ğŸ“„ [CLAWS+](https://ieeexplore.ieee.org/abstract/document/10136845):Clustering aided weakly supervised training to detect anomalous events in surveillance videos, ğŸ“° `TNNLS`

ğŸ—“ï¸ **2024**

- ğŸ“„ [LAP](https://arxiv.org/abs/2403.01169):Learn suspected anomalies from event prompts for video anomaly detection, ğŸ“° `Arxiv`

#### 2.3.5 Knowledge Distillation

ğŸ—“ï¸ **2022**

- ğŸ“„ [MACIL-SD](https://dl.acm.org/doi/abs/10.1145/3503161.3547868):Modality-aware contrastive instance learning with self-distillation for weakly-supervised audio-visual violence detection, ğŸ“° `ACM MM`  [code](https://github.com/JustinYuu/MACIL_SD)

ğŸ—“ï¸ **2023**

- ğŸ“„ [DPK](https://ieeexplore.ieee.org/abstract/document/10136845):Distilling privileged knowledge for anomalous event detection from weakly labeled videos, ğŸ“° `TNNLS`

#### 2.3.6 Leveraging Large Models:

ğŸ—“ï¸ **2023**

- ğŸ“„ [TEVAD](https://openaccess.thecvf.com/content/CVPR2023W/O-DRUM/html/Chen_TEVAD_Improved_Video_Anomaly_Detection_With_Captions_CVPRW_2023_paper.html):Tevad: Improved video anomaly detection with captions, ğŸ“° `CVPRW`

- ğŸ“„ [CLIP-TSA](https://ieeexplore.ieee.org/abstract/document/10222289):Clip-tsa: Clip-assisted temporal self-attention for weakly-supervised video anomaly detection, ğŸ“° `ICIP`  [code](https://github.com/joos2010kj/CLIP-TSA)

ğŸ—“ï¸ **2024**

- ğŸ“„ [UCA](https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Towards_Surveillance_Video-and-Language_Understanding_New_Dataset_Baselines_and_Challenges_CVPR_2024_paper.html):Towards surveillance video-and-language understanding: New dataset baselines and challenges, ğŸ“° `CVPR` [homepage](https://xuange923.github.io/Surveillance-Video-Understanding)

- ğŸ“„ [VadCLIP](https://ojs.aaai.org/index.php/AAAI/article/view/28423):Vadclip: Adapting vision-language models for weakly supervised video anomaly detection, ğŸ“° `AAAI`  [code]( https://github.com/nwpu-zxr/VadCLIP)

- ğŸ“„ [Holmes-VAD](https://arxiv.org/abs/2406.12235):Holmes-vad: Towards unbiased and explainable video anomaly detection via multi-modal llm, ğŸ“° `Arxiv` [code](https://github.com/pipixin321/HolmesVAD) [homepage](https://holmesvad.github.io/)

- ğŸ“„ [VADor w LSTC](https://arxiv.org/abs/2401.05702):Video anomaly detection and explanation via large language models, ğŸ“° `Arxiv`

- ğŸ“„ [LAVAD](https://openaccess.thecvf.com/content/CVPR2024/html/Zanella_Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection_CVPR_2024_paper.html): Harnessing large language models for training-free video anomaly detection, ğŸ“° `CVPR` [code](https://github.com/lucazanella/lavad)  [homepage](https://lucazanella.github.io/lavad/)

- ğŸ“„ [STPrompt](https://arxiv.org/abs/2408.05905):Weakly supervised video anomaly detection and localization with spatio-temporal prompts, ğŸ“° `ACM MM`

### 2.4 Model Output

#### 2.4.1 Frame Level

#### 2.4.2 Pixel Level

ğŸ—“ï¸ **2019**

- ğŸ“„ [Background-bias](https://dl.acm.org/doi/abs/10.1145/3343031.3350998):Exploring background-bias for anomaly detection in surveillance videos, ğŸ“° `ACM MM` [code](https://github.com/xuzero/UCFCrime_BoundingBox_Annotation)

ğŸ—“ï¸ **2021**

- ğŸ“„ [WSSTAD](https://arxiv.org/abs/2108.03825):Weakly-supervised spatio-temporal anomaly detection in surveillance video, ğŸ“° `IJCAI`

## 3. Fully Supervised Video Anomaly Detection

### 3.1 Appearance Input

ğŸ—“ï¸ **2016**

- ğŸ“„ [TS-LSTM](https://link.springer.com/chapter/10.1007/978-981-10-3002-4_43):Multi-stream deep networks for person to person violence detection in videos, ğŸ“° `CCPR`

ğŸ—“ï¸ **2017**

- ğŸ“„ [FightNet](https://iopscience.iop.org/article/10.1088/1742-6596/844/1/012044/meta):Violent interaction detection in video based on deep learning, ğŸ“° `JPCS`

ğŸ—“ï¸ **2019**

- ğŸ“„ [Sub-Vio](https://ieeexplore.ieee.org/abstract/document/8682833):Toward subjective violence detection in videos, ğŸ“° `ICASSP`

- ğŸ“„ [CCTV-Fights](https://ieeexplore.ieee.org/abstract/document/8683676):Detection of real-world fights in surveillance videos, ğŸ“° `ICASSP` [homepage](http://rose1.ntu.edu.sg/Datasets/cctvFights.asp)

### 3.2 Motion Input

ğŸ—“ï¸ **2016**

- ğŸ“„ [TS-LSTM](https://link.springer.com/chapter/10.1007/978-981-10-3002-4_43):Multi-stream deep networks for person to person violence detection in videos, ğŸ“° `CCPR`

ğŸ—“ï¸ **2017**

- ğŸ“„ [ConvLSTM](https://ieeexplore.ieee.org/abstract/document/8078468):Learning to detect violent videos using convolutional long short-term memory, ğŸ“° `AVSS`  [code](https://github.com/swathikirans/violence-recognition-pytorch)

ğŸ—“ï¸ **2018**

- ğŸ“„ [BiConvLSTM](https://openaccess.thecvf.com/content_eccv_2018_workshops/w10/html/Hanson_Bidirectional_Convolutional_LSTM_for_the_Detection_of_Violence_in_Videos_ECCVW_2018_paper.html):Bidirectional convolutional lstm for the detection of violence in videos, ğŸ“° `ECCVW`

ğŸ—“ï¸ **2020**

- ğŸ“„ [MM-VD](https://ieeexplore.ieee.org/abstract/document/9054018):Multimodal violence detection in videos, ğŸ“° `ICASSP`

### 3.3 Skeleton Input

 ğŸ—“ï¸ **2018**

- ğŸ“„ [DSS](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575376):Eye in the sky: Real-time drone surveillance system for violent individuals identification using scatternet hybrid deep learning network, ğŸ“° `CVPRW`
  
  ğŸ—“ï¸ **2020**

- ğŸ“„ [SPIL](https://link.springer.com/chapter/10.1007/978-3-030-58548-8_5):Human interaction learning on 3d skeleton point clouds for video violence recognition, ğŸ“° `ECCV`

### 3.4 Audio Input

 ğŸ—“ï¸ **2020**

- ğŸ“„ [MM-VD](https://ieeexplore.ieee.org/abstract/document/9054018):Multimodal violence detection in videos, ğŸ“° `ICASSP`

### 3.5 Hybrid Input

 ğŸ—“ï¸ **2021**

- ğŸ“„ [FlowGatedNet](https://ieeexplore.ieee.org/abstract/document/9412502):Rwf-2000: an open large scale video database for violence detection, ğŸ“° `ICPR`  [code](https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection)

ğŸ—“ï¸ **2022**

- ğŸ“„ [MutualDis](https://link.springer.com/chapter/10.1007/978-3-031-18913-5_48):Multimodal violent video recognition based on mutual distillation, ğŸ“° `PRCV`

ğŸ—“ï¸ **2023**

- ğŸ“„ [HSCD](https://www.sciencedirect.com/science/article/pii/S1077314223001194): Human skeletons and change detection for efficient violence detection in surveillance videos, ğŸ“° `CVIU`  [code](https://github.com/atmguille/Violence-Detection-With-Human-Skeletons)

## 4. Unsupervised Video Anomaly Detection

### 4.1 Pseudo Label Based Paradigm

 ğŸ—“ï¸ **2018**

- ğŸ“„ [DAW](https://dl.acm.org/doi/abs/10.1145/3240508.3240615):Detecting abnormality without knowing normality: A two-stage approach for unsupervised video abnormal event detection, ğŸ“° `ACM MM`

ğŸ—“ï¸ **2020**

- ğŸ“„ [STDOR](https://openaccess.thecvf.com/content_CVPR_2020/html/Pang_Self-Trained_Deep_Ordinal_Regression_for_End-to-End_Video_Anomaly_Detection_CVPR_2020_paper.html):Self-trained deep ordinal regression for end-to-end video anomaly detection, ğŸ“° `CVPR`

ğŸ—“ï¸ **2022**

- ğŸ“„ [GCL](https://openaccess.thecvf.com/content/CVPR2022/html/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.html):Generative cooperative learning for unsupervised video anomaly detection, ğŸ“° `CVPR`

ğŸ—“ï¸ **2024**

- ğŸ“„ [C2FPL](https://openaccess.thecvf.com/content/WACV2024/html/Al-lahham_A_Coarse-To-Fine_Pseudo-Labeling_C2FPL_Framework_for_Unsupervised_Video_Anomaly_Detection_WACV_2024_paper.html):A coarse-to-fine pseudo-labeling (c2fpl) framework for unsupervised video anomaly detection, ğŸ“° `WACV`  [code](https://github.com/AnasEmad11/C2FPL)

### 4.2 Change Detection Based Paradigm

ğŸ—“ï¸ **2016**

- ğŸ“„ [ADF](https://link.springer.com/chapter/10.1007/978-3-319-46454-1_21):A discriminative framework for anomaly detection in large videos, ğŸ“° `ECCV`  [code](https://github.com/alliedel/anomalyframework_ECCV2016)

ğŸ—“ï¸ **2017**

- ğŸ“„ [Unmasking](https://openaccess.thecvf.com/content_iccv_2017/html/Ionescu_Unmasking_the_Abnormal_ICCV_2017_paper.html):Unmasking the abnormal events in video, ğŸ“° `ICCV`

ğŸ—“ï¸ **2018**

- ğŸ“„ [MC2ST](https://chunliangli.github.io/docs/18bmvcAnomaly.pdf):Classifier two sample test for video anomaly detections, ğŸ“° `BMVC`  [code](https://github.com/MYusha/Video-Anomaly-Detection)

ğŸ—“ï¸ **2022**

- ğŸ“„ [TMAE](https://ieeexplore.ieee.org/abstract/document/9859873):Detecting anomalous events from unlabeled videos via temporal masked autoencoding, ğŸ“° `ICME`

### 4.3 Others

ğŸ—“ï¸ **2021**

- ğŸ“„ [DUAD](https://openaccess.thecvf.com/content/WACV2021/html/Li_Deep_Unsupervised_Anomaly_Detection_WACV_2021_paper.html):Deep unsupervised anomaly detection, ğŸ“° `WACV`

ğŸ—“ï¸ **2022**

- ğŸ“„ [CIL](https://ojs.aaai.org/index.php/AAAI/article/view/20053):A causal inference look at unsupervised video anomaly detection, ğŸ“° `AAAI`

- ğŸ“„ [LBR-SPR](https://openaccess.thecv.com/content/CVPR2022/html/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.html):Deep anomaly discovery from unlabeled videos via normality advantage and self-paced refinement, ğŸ“° `CVPR`  [code](https://github.com/yuguangnudt/LBR_SPR)

## 5. Open Set Supervised Video Anomaly Detection

### 5.1 Open-Set VAD

ğŸ—“ï¸ **2019**

- ğŸ“„ [MLEP](https://www.ijcai.org/proceedings/2019/0419.pdf):Margin learning embedded prediction for video anomaly detection with a few anomalies, ğŸ“° `IJCAI`  [code]( https://github.com/svip-lab/MLEP)

ğŸ—“ï¸ **2022**

- ğŸ“„ [UBnormal](https://openaccess.thecvf.com/content/CVPR2022/html/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.html):Ubnormal: New benchmark for supervised open-set video anomaly detection, ğŸ“° `CVPR`  [code](https://github.com/lilygeorgescu/UBnormal)

- ğŸ“„ [OSVAD](https://link.springer.com/chapter/10.1007/978-3-031-19830-4_23):Towards open set video anomaly detection, ğŸ“° `ECCV`

ğŸ—“ï¸ **2024**

- ğŸ“„ [OVVAD](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Open-Vocabulary_Video_Anomaly_Detection_CVPR_2024_paper.html):Open-vocabulary video anomaly detection, ğŸ“° `CVPR`

### 5.2 Few-Shot VAD

ğŸ—“ï¸ **2020**

- ğŸ“„ [FSSA](https://link.springer.com/chapter/10.1007/978-3-030-58558-7_8):Few-shot scene-adaptive anomaly detection, ğŸ“° `ECCV`  [code](https://github.com/yiweilu3/Few-shot-Scene-adaptive-Anomaly-Detection)

ğŸ—“ï¸ **2021**

- ğŸ“„ [AADNet](https://link.springer.com/chapter/10.1007/978-3-030-88007-1_26):Adaptive anomaly detection network for unseen scene without fine-tuning, ğŸ“° `PRCV`

ğŸ—“ï¸ **2022**

- ğŸ“„ [VADNet](https://ieeexplore.ieee.org/abstract/document/9976040):Boosting variational inference with margin learning for few-shot scene-adaptive anomaly detection, ğŸ“° `TCSVT`  [code](https://github.com/huangxx156/VADNet)

ğŸ—“ï¸ **2023**

- ğŸ“„ [zxVAD](https://openaccess.thecvf.com/content/WACV2023/html/Aich_Cross-Domain_Video_Anomaly_Detection_Without_Target_Domain_Adaptation_WACV_2023_paper.html):Cross-domain video anomaly detection without target domain adaptation, ğŸ“° `WACV`

## Performance Comparison

The following tables are the performance comparison of semi-supervised VAD, weakly supervised VAD, fully supervised VAD, and unsupervised VAD methods as reported in the literature. For semi-supervised, weakly supervised, and unsupervised VAD methods, the evaluation metric used is AUC (%) and AP ( XD-Violence, %), while for  fully supervised VAD methods, the metric is Accuracy (%).

- **Quantitative Performance Comparison of Semi-supervised Methods on Public Datasets.**

| Method     | Publication | Methodology            | Ped1 | Ped2 | Avenue | ShanghaiTech | UBnormal |
| ---------- | -----------:| ---------------------- |:----:|:----:|:------:|:------------:|:--------:|
| AMDN       | BMVC 2015   | One-class classifier   | 92.1 | 90.8 | -      | -            | -        |
| ConvAE     | CVPR 2016   | Reconstruction         | 81.0 | 90.0 | 72.0   | -            | -        |
| STAE       | ACMMM 2017  | Hybrid                 | 92.3 | 91.2 | 80.9   | -            | -        |
| StackRNN   | ICCV 2017   | Sparse coding          | -    | 92.2 | 81.7   | 68.0         | -        |
| FuturePred | CVPR 2018   | Prediction             | 83.1 | 95.4 | 85.1   | 72.8         | -        |
| DeepOC     | TNNLS 2019  | One-class classifier   | 83.5 | 96.9 | 86.6   | -            | -        |
| MemAE      | ICCV 2019   | Reconstruction         | -    | 94.1 | 83.3   | 71.2         | -        |
| AnoPCN     | ACMMM 2019  | Prediction             | -    | 96.8 | 86.2   | 73.6         | -        |
| ObjectAE   | CVPR 2019   | One-class classifier   | -    | 97.8 | 90.4   | 84.9         | -        |
| BMAN       | TIP 2019    | Prediction             | -    | 96.6 | 90.0   | 76.2         | -        |
| sRNN-AE    | TPAMI 2019  | Sparse coding          | -    | 92.2 | 83.5   | 69.6         | -        |
| ClusterAE  | ECCV 2020   | Reconstruction         | -    | 96.5 | 86.0   | 73.3         | -        |
| MNAD       | CVPR 2020   | Reconstruction         | -    | 97.0 | 88.5   | 70.5         | -        |
| VEC        | ACMMM 2020  | Cloze test             | -    | 97.3 | 90.2   | 74.8         | -        |
| AMMC-Net   | AAAI 2021   | Prediction             | -    | 96.6 | 86.6   | 73.7         | -        |
| MPN        | CVPR 2021   | Prediction             | 85.1 | 96.9 | 89.5   | 73.8         | -        |
| HF$^2$-VAD | ICCV 2021   | Hybrid                 | -    | 99.3 | 91.1   | 76.2         | -        |
| BAF        | TPAMI 2021  | One-class classifier   |      | 98.7 | 92.3   | 82.7         | 59.3     |
| Multitask  | CVPR 2021   | Multiple tasks         | -    | 99.8 | 92.8   | 90.2         | -        |
| F$^2$PN    | TPAMI 2022  | Prediction             | 84.3 | 96.2 | 85.7   | 73.0         | -        |
| DLAN-AC    | ECCV 2022   | Reconstruction         | -    | 97.6 | 89.9   | 74.7         | -        |
| BDPN       | AAAI 2022   | Prediction             | -    | 98.3 | 90.3   | 78.1         | -        |
| CAFÃ‰       | ACMMM 2022  | Prediction             | -    | 98.4 | 92.6   | 77.0         | -        |
| STJP       | ECCV 2022   | Jigsaw puzzle          | -    | 99.0 | 92.2   | 84.3         | 56.4     |
| MPT        | ICCV 2023   | Multiple tasks         | -    | 97.6 | 90.9   | 78.8         | -        |
| HSC        | CVPR 2023   | Hybrid                 | -    | 98.1 | 93.7   | 83.4         | -        |
| LERF       | AAAI 2023   | Predicition            | -    | 99.4 | 91.5   | 78.6         | -        |
| DMAD       | CVPR 2023   | Reconstruction         | -    | 99.7 | 92.8   | 78.8         | -        |
| EVAL       | CVPR 2023   | Interpretable learning | -    | -    | 86.0   | 76.6         | -        |
| FBSC-AE    | CVPR 2023   | Prediction             | -    | -    | 86.8   | 79.2         | -        |
| FPDM       | ICCV 2023   | Prediction             | -    | -    | 90.1   | 78.6         | 62.7     |
| PFMF       | CVPR 2023   | Multiple tasks         | -    | -    | 93.6   | 85.0         | -        |
| STG-NF     | ICCV 2023   | Gaussian classifier    | -    | -    | -      | 85.9         | 71.8     |
| AED-MAE    | CVPR 2024   | Patch inpainting       | -    | 95.4 | 91.3   | 79.1         | 58.5     |
| SSMCTB     | TPAMI 2024  | Patch inpainting       | -    | -    | 91.6   | 83.7         | -        |

- **Quantitative Performance Comparison of Weakly Supervised Methods on Public Datasets.**
  
  | Method   | Publication | Feature        | UCF-Crime | XD-Violence | ShanghaiTech | TAD   |
  | -------- | -----------:| -------------- |:---------:|:-----------:|:------------:|:-----:|
  | DeepMIL  | CVPR 2018   | C3D(RGB)       | 75.40     | -           | -            | -     |
  | GCN      | CVPR 2019   | TSN(RGB)       | 82.12     | -           | 84.44        | -     |
  | HLNet    | ECCV 2020   | I3D(RGB)       | 82.44     | 75.41       | -            | -     |
  | CLAWS    | ECCV 2020   | C3D(RGB)       | 83.03     | -           | 89.67        | -     |
  | MIST     | CVPR 2021   | I3D(RGB)       | 82.30     | -           | 94.83        | -     |
  | RTFM     | ICCV 2021   | I3D(RGB)       | 84.30     | 77.81       | 97.21        | -     |
  | CTR      | TIP 2021    | I3D(RGB)       | 84.89     | 75.90       | 97.48        | -     |
  | MSL      | AAAI 2022   | VideoSwin(RGB) | 85.62     | 78.59       | 97.32        | -     |
  | S3R      | ECCV 2022   | I3D(RGB)       | 85.99     | 80.26       | 97.48        | -     |
  | SSRL     | ECCV 2022   | I3D(RGB)       | 87.43     | -           | 97.98        | -     |
  | CMRL     | CVPR 2023   | I3D(RGB)       | 86.10     | 81.30       | 97.60        | -     |
  | CUPL     | CVPR 2023   | I3D(RGB)       | 86.22     | 81.43       | -            | 91.66 |
  | MGFN     | AAAI 2023   | VideoSwin(RGB) | 86.67     | 80.11       | -            | -     |
  | UMIL     | CVPR 2023   | CLIP           | 86.75     | -           | -            | 92.93 |
  | DMU      | AAAI 2023   | I3D(RGB)       | 86.97     | 81.66       | -            | -     |
  | PE-MIL   | CVPR 2024   | I3D(RGB)       | 86.83     | 88.05       | 98.35        | -     |
  | TPWNG    | CVPR 2024   | CLIP           | 87.79     | 83.68       | -            | -     |
  | VadCLIP  | AAAI 2024   | CLIP           | 88.02     | 84.51       | -            | -     |
  | STPrompt | ACMMM 2024  | CLIP           | 88.08     | -           | 97.81        | -     |

- **Quantitative Performance Comparison of Fully Supervised Methods on Public Datasets.**
  
  | Method       | Publication | Model Input               | Hockey Fights | Violent-Flows | RWF-2000 | Crowed Violence |
  | ------------ | ----------- | ------------------------- | ------------- | ------------- | -------- | --------------- |
  | TS-LSTM      | PR 2016     | RGB+Flow                  | 93.9          | -             | -        | -               |
  | FightNet     | JPCS 2017   | RGB+Flow                  | 97.0          | -             | -        | -               |
  | ConvLSTM     | AVSS 2017   | Frame Difference          | 97.1          | 94.6          | -        | -               |
  | BiConvLSTM   | ECCVW 2018  | Frame Difference          | 98.1          | 96.3          | -        | -               |
  | SPIL         | ECCV 2020   | Skeleton                  | 96.8          | -             | 89.3     | 94.5            |
  | FlowGatedNet | ICPR 2020   | RGB+Flow                  | 98.0          | -             | 87.3     | 88.9            |
  | X3D          | AVSS 2022   | RGB                       | -             | 98.0          | 94.0     | -               |
  | HSCD         | CVIU 2023   | Skeleton+Frame Difference | 94.5          | -             | 90.3     | 94.3            |

- **Quantitative Performance Comparison of Unsupervised Methods on Public Datasets.**
  
  | Method    | Publication | Methodology      | Avenue | Subway Exit | Ped1 | Ped2 | ShaihaiTech | UMN  |
  | --------- | ----------- | ---------------- | ------ | ----------- | ---- | ---- | ----------- | ---- |
  | ADF       | ECCV 2016   | Change detection | 78.3   | 82.4        | -    | -    | -           | 91.0 |
  | Unmasking | ICCV 2017   | Change detection | 80.6   | 86.3        | 68.4 | 82.2 | -           | 95.1 |
  | MC2ST     | BMVC 2018   | Change detection | 84.4   | 93.1        | 71.8 | 87.5 | -           | -    |
  | DAW       | ACMMM 2018  | Pseudo label     | 85.3   | 84.5        | 77.8 | 96.4 | -           | -    |
  | STDOR     | CVPR 2020   | Pseudo label     | -      | 92.7        | 71.7 | 83.2 | -           | 97.4 |
  | TMAE      | ICME 2022   | Change detection | 89.8   | -           | 75.7 | 94.1 | 71.4        | -    |
  | CIL       | AAAI 2022   | Others           | 90.3   | 97.6        | 84.9 | 99.4 | -           | 100  |
  | LBR-SPR   | CVPR 2022   | Others           | 92.8   | -           | 81.1 | 97.2 | 72.6        | -    |

## Citation

If you find our work useful, please cite our paper:

```
@article{wu2024deep,
  title={Deep Learning for Video Anomaly Detection: A Review},
  author={Wu, Peng and Pan, Chengyu and Yan, Yuting and Pang, Guansong and Wang, Peng and Zhang, Yanning},
  journal={arXiv preprint arXiv:xxxxx},
  year={2024}
}
```
